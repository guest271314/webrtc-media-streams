<pre class='metadata'>
Title: WebRTC Insertable Media using Streams
Shortname: webrtc-media-streams
Level: None
Status: ED
Group: webrtc
Repository: w3c/webrtc-insertable-streams/
URL: https://w3c.github.io/webrtc-insertable-streams/
Editor: Harald Alvestrand, Google https://google.com, hta@google.com
Editor: Guido Urdaneta, Google https://google.com, guidou@google.com
Abstract: This API defines an API surface for manipulating the bits on
Abstract: MediaStreamTracks being sent via an RTCPeerConnection.
Markup Shorthands: css no, markdown yes
</pre>
<pre class='anchors'>
spec: WEBRTC; urlPrefix: https://w3c.github.io/webrtc-pc/
    type: interface
        text: RTCPeerConnection; url: #dom-rtcpeerconnection
    type: dictionary
        text: RTCConfiguration; url: #dom-rtcconfiguration
spec: WEB-CODECS; urlPrefix: https://github.com/WICG/web-codecs/
    type: interface
        text: AudioEncoder; url: #dom-audioencoder
    type: interface
        text: AudioDecoder; url: #dom-audiodecoder
    type: interface
        text: VideoEncoder; url: #dom-videoencoder
    type: interface
        text: VideoDecoder; url: #dom-videodecoder
</pre>
<pre class=biblio>
{
  "WEB-CODECS": {
     "href":
     "https://github.com/WICG/web-codecs/blob/master/explainer.md",
     "title": "Web Codecs explainer"
   }
}
</pre>
<pre class=link-defaults>
spec:streams; type:interface; text:ReadableStream
</pre>

# Introduction # {#introduction}

The [[WEBRTC-NV-USE-CASES]] document describes several functions that
can only be achieved by access to media (requirements N20-N22),
including, but not limited to:
* Funny Hats
* Machine Learning
* Virtual Reality Gaming

These use cases further require that processing can be done in worker
threads (requirement N23-N24).

Furthermore, the "trusted JavaScript cloud conferencing" use case
requires such processing to be done on encoded media, not just the raw
media.

This specification gives an interface inspired by [[WEB-CODECS]] to
provide access to such functionality while retaining the setup flow of
RTCPeerConnection.

This iteration of the specification provides access to encoded media,
which is the output of the encoder part of a codec and the input to the
decoder part of a codec.

# Terminology # {#terminology}

# Specification # {#specification}

The Streams definition doesn't use WebIDL much, but the WebRTC spec does.
This specification shows the IDL extensions for WebRTC.

It uses an extension to RTCConfiguration in order to notify the
{{RTCPeerConnection}} that insertable streams will be used, and uses
an additional API on {{RTCRtpSender}} and {{RTCRtpReceiver}} to
insert the processing into the pipeline.

<pre class="idl">
// New dictionary.
dictionary RTCInsertableStreams {
    ReadableStream readable;
    WritableStream writable;
};

// New enum for video frame types. Will eventually re-use the equivalent defined
// by WebCodecs.
enum RTCEncodedVideoFrameType {
    "empty",
    "key",
    "delta",
};

dictionary RTCEncodedVideoFrameMetadata {
    long long frameId;
    sequence&lt;long long&gt; dependencies;
    unsigned short width;
    unsigned short height;
    long spatialIndex;
    long temporalIndex;
    long synchronizationSource;
    sequence&lt;long&gt; contributingSources;
};

// New interfaces to define encoded video and audio frames. Will eventually
// re-use or extend the equivalent defined in WebCodecs.
interface RTCEncodedVideoFrame {
    readonly attribute RTCEncodedVideoFrameType type;
    readonly attribute unsigned long long timestamp;
    attribute ArrayBuffer data;
    RTCEncodedVideoFrameMetadata getMetadata();
};

dictionary RTCEncodedAudioFrameMetadata {
    long synchronizationSource;
    sequence&lt;long&gt; contributingSources;
};

interface RTCEncodedAudioFrame {
    readonly attribute unsigned long long timestamp;
    attribute ArrayBuffer data;
    RTCEncodedAudioFrameMetadata getMetadata();
};


// New fields in RTCConfiguration
partial dictionary RTCConfiguration {
    boolean encodedInsertableStreams = false;
};

// New methods for RTCRtpSender and RTCRtpReceiver
partial interface RTCRtpSender {
    RTCInsertableStreams createEncodedStreams();
};

partial interface RTCRtpReceiver {
    RTCInsertableStreams createEncodedStreams();
};
</pre>

## Extension operation ## {#operation}

At the time when a codec is initialized as part of the encoder, and the
corresponding flag is set in the {{RTCPeerConnection}}'s {{RTCConfiguration}}
argument, ensure that the codec is disabled and produces no output.


### Stream creation ### {#stream-creation}

Let the {{RTCRtpSender}} or {{RTCRtpReceiver}} have an internal slot,
[[\Streams]], initialized to null.

When {{RTCRtpSender/createEncodedStreams}}() is
called, run the following steps:

* If the {{RTCPeerConnection}}'s configuration does not have {{RTCConfiguration/encodedInsertableStreams}} set to "true", throw an {{InvalidStateError}} and abort these steps.
* If the data source does not permit access, throw an {{InvalidAccessError}} and abort these steps.
* If [[\Streams]] is not null, throw an {{InvalidStateError}}.
* Create an {{RTCInsertableStreams}} object 's'.
* Set s.readable to a ReadableStream representing the encoded data source.
* Set s.writable to a WritableStream representing the encoded data sink.
* Enable the encoded data source.
* Store 's' in the internal slot [[\Streams]].
* Return 's'

### Stream processing ### {#stream-processing}

When a frame is produced from the encoded data source, place it on the
[[\Streams]].readableStream'.

When a frame appears on the [[\Streams]].writable, do the following:
* Check that the frame is a a valid frame that has been created by the encoded data source; if it is not, discard it. A processor cannot create frames, or move frames between streams.
* Check that the frame's {{RTCEncodedVideoFrame/timestamp}} is equal to or larger than any previously received frame. A processor cannot reorder frames, although it may delay them or drop them. 
* Process the frame as if it came directly from the encoded data source.

# Privacy and security considerations # {#privacy}

This API gives Javascript access to the content of media streams. This
is also available from other sources, such as Canvas and WebAudio.

However, streams that are isolated (as specified in
[[WEBRTC-IDENTITY]]) or tainted with another origin, cannot be
accessed using this API, since that would break the isolation rule.

The API will allow access to some aspects of timing information that are
otherwise unavailable, which allows some fingerprinting surface.


# Examples # {#examples}

See the explainer document.


